{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ClinicalCoding: Transformers.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "eZ5cesVJtug1"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xuFZCjyK13F"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxN8oQWJkK79"
      },
      "source": [
        "# **Setup**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7ij__fDsvmQ"
      },
      "source": [
        "!pip install transformers >> /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qqh2fBh3JxkP"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "import re\n",
        "import pickle\n",
        "from tqdm import tqdm, trange\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, multilabel_confusion_matrix, f1_score, accuracy_score\n",
        "\n",
        "from torch.nn import BCEWithLogitsLoss, BCELoss\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzUw21uktG6z"
      },
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65aUETg_tG5b"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "torch.cuda.get_device_name(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKaz4I-3mb5F"
      },
      "source": [
        "threshold = 0.20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cI8G-A6DmGTa"
      },
      "source": [
        "# **D-subtask** *English*: **Data Loader**\n",
        "\n",
        "X_train, X_val, X_test: list of *input text data*\n",
        "\n",
        "Y_train, Y_val, Y_test: list of one-hot encoded *labels*\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uB01d6zVKLVh"
      },
      "source": [
        "df_train = pd.read_csv('drive/MyDrive/CodiEsp/train/trainD.tsv', sep = '\\t', header = None)\n",
        "df_train.rename(columns = {0:\"Id\", 1:\"ICD10\"}, inplace = True)\n",
        "print(\"Training Data:\")\n",
        "display(df_train.head())\n",
        "\n",
        "print(\"\\n\\nValidation Data:\")\n",
        "df_val = pd.read_csv('drive/MyDrive/CodiEsp/dev/devD.tsv', sep = '\\t', header = None)\n",
        "df_val.rename(columns = {0:\"Id\", 1:\"ICD10\"}, inplace = True)\n",
        "display(df_val.head())\n",
        "\n",
        "print(\"\\n\\nTest Data:\")\n",
        "df_test = pd.read_csv('drive/MyDrive/CodiEsp/test/testD.tsv', sep = '\\t', header = None)\n",
        "df_test.rename(columns = {0:\"Id\", 1:\"ICD10\"}, inplace = True)\n",
        "display(df_test.head())\n",
        "\n",
        "df = pd.concat([df_train, df_val, df_test])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Lyflba-KT-k"
      },
      "source": [
        "ids = df['Id'].unique()\n",
        "codes = df['ICD10'].unique()  \n",
        "\n",
        "print(\"Number of documents in training data:\", len(\n",
        "    ids), \"\\nNumber of ICD10 codes:\", len(codes))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQ9m5j90K4qf"
      },
      "source": [
        "code2idx = {}\n",
        "for i in range(len(codes)):\n",
        "  code2idx[codes[i]] = i\n",
        "\n",
        "id2label = {}\n",
        "for i in range(len(ids)):\n",
        "  id2label[ids[i]] = [0]*len(codes)\n",
        "\n",
        "for i, data in df.iterrows():\n",
        "  _id = data[0]\n",
        "  _code = data[1]\n",
        "  id2label[_id][code2idx[_code]] = 1\n",
        "\n",
        "_id2label = [(id, y) for id, y in id2label.items()]\n",
        "ID, Y = zip(*_id2label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1475dI1Rv_H"
      },
      "source": [
        "def remstopwords(text, stopwords):\n",
        "    text = re.sub('\\[\\*\\*[^\\]]*\\*\\*\\]', '', text)\n",
        "    text = re.sub('<[^>]*>', '', text)\n",
        "    text = re.sub('[\\W]+', ' ', text.lower()) \n",
        "    text = re.sub(\" \\d+\", \" \", text)\n",
        "    return \" \".join([i for i in text.split() if i not in stopwords])\n",
        "\n",
        "stop_words = stopwords.words('english')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15CTLWqbTqfG"
      },
      "source": [
        "X_train = []\n",
        "Y_train = []\n",
        "\n",
        "for id in (df_train['Id'].unique()):\n",
        "  Y_train.append(id2label[id])\n",
        "\n",
        "  with open('drive/MyDrive/CodiEsp/train/text_files_en/' + id + '.txt', 'r') as f:\n",
        "    text = f.read().replace('\\n', ' ')\n",
        "  X_train.append(remstopwords(text.lower(), stop_words))\n",
        "with open(\"drive/MyDrive/X_train.txt\", \"wb\") as fp:\n",
        "  pickle.dump(X_train, fp)\n",
        "with open(\"drive/MyDrive/X_train.txt\", \"rb\") as fp:\n",
        "  X_train = pickle.load(fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSEBnCXYlVc0"
      },
      "source": [
        "X_val = []\n",
        "Y_val = []\n",
        "\n",
        "for id in (df_val['Id'].unique()):\n",
        "  Y_val.append(id2label[id])\n",
        "\n",
        "  with open('drive/MyDrive/CodiEsp/dev/text_files_en/' + id + '.txt', 'r') as f:\n",
        "    text = f.read().replace('\\n', ' ')\n",
        "  X_val.append(remstopwords(text.lower(), stop_words))\n",
        "with open(\"drive/MyDrive/X_val.txt\", \"wb\") as fp:\n",
        "  pickle.dump(X_val, fp)\n",
        "with open(\"drive/MyDrive/X_val.txt\", \"rb\") as fp:\n",
        "  X_val = pickle.load(fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyfJSWRjmsou"
      },
      "source": [
        "X_test = []\n",
        "Y_test = []\n",
        "\n",
        "for id in (df_test['Id'].unique()):\n",
        "  Y_test.append(id2label[id])\n",
        "\n",
        "  with open('drive/MyDrive/CodiEsp/test/text_files_en/' + id + '.txt', 'r') as f:\n",
        "    text = f.read().replace('\\n', ' ')\n",
        "  X_test.append(remstopwords(text.lower(), stop_words))\n",
        "with open(\"drive/MyDrive/X_test.txt\", \"wb\") as fp:\n",
        "  pickle.dump(X_test, fp)\n",
        "with open(\"drive/MyDrive/X_test.txt\", \"rb\") as fp:\n",
        "  X_test = pickle.load(fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3zjE9FgnGd_"
      },
      "source": [
        "p_code = [0]*len(codes)\n",
        "for label in Y_train:\n",
        "  for i, code in enumerate(label):\n",
        "    if (code == 1):\n",
        "      p_code[i] = 1\n",
        "\n",
        "not_present = 0\n",
        "for i, present in enumerate(p_code):\n",
        "  if (present == 0):\n",
        "    not_present += 1\n",
        "\n",
        "print(\"Number of classes NOT PRESENT in training dataset:\", not_present)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZ5cesVJtug1"
      },
      "source": [
        "# **D-subtask** *English*: **BERT Model**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aMDGWBScjxF"
      },
      "source": [
        "from transformers import AdamW\n",
        "from transformers import BertTokenizer, BertForSequenceClassification"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVs86F-tpUJb"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case = True)\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels = len(codes))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65xtR35FtuPh"
      },
      "source": [
        "encodings_train = tokenizer.batch_encode_plus(X_train, max_length = 512, padding = True, truncation = True)\n",
        "encodings_val = tokenizer.batch_encode_plus(X_val, max_length = 512, padding = True, truncation = True)\n",
        "encodings_test = tokenizer.batch_encode_plus(X_test, max_length = 512, padding = True, truncation = True)\n",
        "\n",
        "print('tokenizer outputs: ', encodings_train.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "At5Le-pTvw-5"
      },
      "source": [
        "# Convert all of our data into torch tensors, the required datatype for our model\n",
        "train_inputs = torch.tensor(encodings_train['input_ids'])\n",
        "train_labels = torch.tensor(Y_train)\n",
        "train_masks = torch.tensor(encodings_train['attention_mask'])\n",
        "train_token_types = torch.tensor(encodings_train['token_type_ids'])\n",
        "\n",
        "val_inputs = torch.tensor(encodings_val['input_ids'])\n",
        "val_labels = torch.tensor(Y_val)\n",
        "val_masks = torch.tensor(encodings_val['attention_mask'])\n",
        "val_token_types = torch.tensor(encodings_val['token_type_ids'])\n",
        "\n",
        "test_inputs = torch.tensor(encodings_test['input_ids'])\n",
        "test_labels = torch.tensor(Y_test)\n",
        "test_masks = torch.tensor(encodings_test['attention_mask'])\n",
        "test_token_types = torch.tensor(encodings_test['token_type_ids'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OuzTEtmv6WU"
      },
      "source": [
        "batch_size = 6\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels, train_token_types)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size = batch_size)\n",
        "\n",
        "val_data = TensorDataset(val_inputs, val_masks, val_labels, val_token_types)\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size = batch_size)\n",
        "\n",
        "test_data = TensorDataset(test_inputs, test_masks, test_labels, test_token_types)\n",
        "test_sampler = SequentialSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size = batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KmNMr13v6MU"
      },
      "source": [
        "model.cuda(device = device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKxLw51fx0ja"
      },
      "source": [
        "optimizer = AdamW(model.parameters(), lr = 2e-5)  # Default optimization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qeysj2ZR3JTl"
      },
      "source": [
        "for param in model.base_model.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ap4ZU1mJyWJR"
      },
      "source": [
        "def hamming_score(y_true, y_pred):\n",
        "    ''' Compute the Hamming score (a.k.a. label-based accuracy) for the multi-label case\n",
        "        http://stackoverflow.com/q/32239577/395857 '''\n",
        "\n",
        "    acc_list = []\n",
        "    for i in range(y_true.shape[0]):\n",
        "        set_true = set(np.where(y_true[i])[0])\n",
        "        set_pred = set(np.where(y_pred[i])[0])\n",
        "        tmp_a = None\n",
        "        if len(set_true) == 0 and len(set_pred) == 0:\n",
        "            tmp_a = 1\n",
        "        else:\n",
        "            tmp_a = len(set_true.intersection(set_pred))/float(len(set_true.union(set_pred)))\n",
        "        acc_list.append(tmp_a)\n",
        "    return np.mean(acc_list)   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysbKjmmnx8L-"
      },
      "source": [
        "# Store our loss and accuracy for plotting\n",
        "train_loss_set = []\n",
        "max_val_f1score = 0.0\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 4\n",
        "\n",
        "# trange is a tqdm wrapper around the normal python range\n",
        "for _ in trange(epochs, desc = \"Epoch\"):\n",
        "\n",
        "  # Training\n",
        "  \n",
        "  # Set our model to training mode (as opposed to evaluation mode)\n",
        "  model.train()\n",
        "\n",
        "  # Tracking variables\n",
        "  tr_loss = 0 #running loss\n",
        "  nb_tr_examples, nb_tr_steps = 0, 0\n",
        "  \n",
        "  # Train the data for one epoch\n",
        "  for step, batch in enumerate(train_dataloader):\n",
        "    batch = tuple(t.to(device) for t in batch) # Add batch to GPU\n",
        "    b_input_ids, b_input_mask, b_labels, b_token_types = batch # Unpack the inputs from our dataloader\n",
        "    optimizer.zero_grad() # Clear out the gradients (by default they accumulate)\n",
        "\n",
        "    outputs = model(b_input_ids, token_type_ids = None, attention_mask = b_input_mask) # Forward pass for multilabel classification\n",
        "\n",
        "    logits = outputs[0]\n",
        "    loss_func = BCEWithLogitsLoss() \n",
        "    loss = loss_func(logits.view(-1, len(codes)), b_labels.type_as(logits).view(-1, len(codes))) #convert labels to float for calculation\n",
        "    train_loss_set.append(loss.item())    \n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Update tracking variables\n",
        "    tr_loss += loss.item()\n",
        "    nb_tr_examples += b_input_ids.size(0)\n",
        "    nb_tr_steps += 1\n",
        "\n",
        "  print(\"\\nTrain loss: {}\".format(tr_loss/nb_tr_steps))\n",
        "\n",
        "###############################################################################\n",
        "\n",
        "  # Validation\n",
        "\n",
        "  # Put model in evaluation mode to evaluate loss on the validation set\n",
        "  model.eval()\n",
        "\n",
        "  # Variables to gather full output\n",
        "  logit_preds, true_labels, pred_labels, tokenized_texts = [], [], [], []\n",
        "\n",
        "  for i, batch in enumerate(val_dataloader):\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    b_input_ids, b_input_mask, b_labels, b_token_types = batch\n",
        "    \n",
        "    with torch.no_grad():\n",
        "      outs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "      b_logit_pred = outs[0]\n",
        "      pred_label = torch.sigmoid(b_logit_pred)\n",
        "\n",
        "      b_logit_pred = b_logit_pred.detach().cpu().numpy()\n",
        "      pred_label = pred_label.to('cpu').numpy()\n",
        "      b_labels = b_labels.to('cpu').numpy()\n",
        "\n",
        "    tokenized_texts.append(b_input_ids)\n",
        "    logit_preds.append(b_logit_pred)\n",
        "    true_labels.append(b_labels)\n",
        "    pred_labels.append(pred_label)\n",
        "\n",
        "  # Flatten outputs\n",
        "  pred_labels = [item for sublist in pred_labels for item in sublist]\n",
        "  true_labels = [item for sublist in true_labels for item in sublist]\n",
        "\n",
        "  # Calculate Accuracy\n",
        "  pred_bools = [pl > threshold for pl in pred_labels]\n",
        "  true_bools = [tl == 1 for tl in true_labels]\n",
        "\n",
        "  val_f1_accuracy = f1_score(true_bools, pred_bools,average = 'macro')\n",
        "  val_flat_accuracy = accuracy_score(true_bools, pred_bools)\n",
        "  val_hamming_score = hamming_score(np.array(true_bools), np.array(pred_bools))\n",
        "\n",
        "  # if (max_val_f1score <= val_f1_accuracy):\n",
        "  #   torch.save(model.state_dict(), 'drive/MyDrive/BEST_BertModel.pt')\n",
        "\n",
        "  print('\\nF1 Validation Accuracy: ', val_f1_accuracy)\n",
        "  print('Flat Validation Accuracy: ', val_flat_accuracy)\n",
        "  print(\"Validation Hamming Score \", val_hamming_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ig0q9afoyFEr"
      },
      "source": [
        "torch.save(model.state_dict(), 'drive/MyDrive/BEST_BertModelD.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zU04W6d0yFBo"
      },
      "source": [
        "model.load_state_dict(torch.load('drive/MyDrive/BEST_BertModelD.pt'))\n",
        "model.eval()\n",
        "\n",
        "# Variables to gather full output\n",
        "logit_preds, true_labels, pred_labels, tokenized_texts = [], [], [], []\n",
        "\n",
        "for i, batch in enumerate(test_dataloader):\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  b_input_ids, b_input_mask, b_labels, b_token_types = batch\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    outs = model(b_input_ids, token_type_ids = None, attention_mask = b_input_mask)\n",
        "    b_logit_pred = outs[0]\n",
        "    pred_label = torch.sigmoid(b_logit_pred)\n",
        "\n",
        "    b_logit_pred = b_logit_pred.detach().cpu().numpy()\n",
        "    pred_label = pred_label.to('cpu').numpy()\n",
        "    b_labels = b_labels.to('cpu').numpy()\n",
        "\n",
        "  tokenized_texts.append(b_input_ids)\n",
        "  logit_preds.append(b_logit_pred)\n",
        "  true_labels.append(b_labels)\n",
        "  pred_labels.append(pred_label)\n",
        "\n",
        "# Flatten outputs\n",
        "pred_labels = [item for sublist in pred_labels for item in sublist]\n",
        "true_labels = [item for sublist in true_labels for item in sublist]\n",
        "\n",
        "# Calculate Accuracy\n",
        "pred_bools = [pl > threshold for pl in pred_labels]\n",
        "true_bools = [tl == 1 for tl in true_labels]\n",
        "\n",
        "test_f1_accuracy = f1_score(true_bools, pred_bools,average = 'macro')\n",
        "test_flat_accuracy = accuracy_score(true_bools, pred_bools)\n",
        "test_hamming_score = hamming_score(np.array(true_bools), np.array(pred_bools))\n",
        "\n",
        "print('\\nF1 Test Accuracy: ', test_f1_accuracy)\n",
        "print('Flat Test Accuracy: ', test_flat_accuracy)\n",
        "print(\"Test Hamming Score \", test_hamming_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGUZeF7y4vf9"
      },
      "source": [
        "# **D-subtask** *English*: **Bio_Clinical BERT Model**\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xG-8OVMp5FYA"
      },
      "source": [
        "def hamming_score(y_true, y_pred):\n",
        "    ''' Compute the Hamming score (a.k.a. label-based accuracy) for the multi-label case\n",
        "        http://stackoverflow.com/q/32239577/395857 '''\n",
        "\n",
        "    acc_list = []\n",
        "    for i in range(y_true.shape[0]):\n",
        "        set_true = set(np.where(y_true[i])[0])\n",
        "        set_pred = set(np.where(y_pred[i])[0])\n",
        "        tmp_a = None\n",
        "        if len(set_true) == 0 and len(set_pred) == 0:\n",
        "            tmp_a = 1\n",
        "        else:\n",
        "            tmp_a = len(set_true.intersection(set_pred))/float(len(set_true.union(set_pred)))\n",
        "        acc_list.append(tmp_a)\n",
        "    return np.mean(acc_list)   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JWk2FeplwN2"
      },
      "source": [
        "from transformers import AdamW\n",
        "from transformers import AutoTokenizer, AutoModel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CLZO_jjEZwi"
      },
      "source": [
        "len(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wevI0nnM4Nt7"
      },
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
        "\n",
        "encodings_train = tokenizer.batch_encode_plus(X_train, max_length = 512, padding = True, truncation = True)\n",
        "encodings_val = tokenizer.batch_encode_plus(X_val, max_length = 512, padding = True, truncation = True)\n",
        "encodings_test = tokenizer.batch_encode_plus(X_test, max_length = 512, padding = True, truncation = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2OXgLHq4Q25"
      },
      "source": [
        "# Convert all of our data into torch tensors, the required datatype for our model\n",
        "train_inputs = torch.tensor(encodings_train['input_ids'])\n",
        "train_labels = torch.tensor(Y_train)\n",
        "train_masks = torch.tensor(encodings_train['attention_mask'])\n",
        "# train_token_types = torch.tensor(encodings_train['token_type_ids'])\n",
        "\n",
        "val_inputs = torch.tensor(encodings_val['input_ids'])\n",
        "val_labels = torch.tensor(Y_val)\n",
        "val_masks = torch.tensor(encodings_val['attention_mask'])\n",
        "# val_token_types = torch.tensor(encodings_val['token_type_ids'])\n",
        "\n",
        "test_inputs = torch.tensor(encodings_test['input_ids'])\n",
        "test_labels = torch.tensor(Y_test)\n",
        "test_masks = torch.tensor(encodings_test['attention_mask'])\n",
        "# test_token_types = torch.tensor(encodings_test['token_type_ids'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcjgJyKX444y"
      },
      "source": [
        "batch_size = 5\n",
        "\n",
        "# train_data = TensorDataset(train_inputs, train_masks, train_labels, train_token_types)\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler = train_sampler, batch_size = batch_size)\n",
        "\n",
        "# val_data = TensorDataset(val_inputs, val_masks, val_labels, val_token_types)\n",
        "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size = batch_size)\n",
        "\n",
        "# test_data = TensorDataset(test_inputs, test_masks, test_labels, test_token_types)\n",
        "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
        "test_sampler = SequentialSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler = test_sampler, batch_size = batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPLrmxCq7Kpl"
      },
      "source": [
        "class BioBERT(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(BioBERT, self).__init__()\n",
        "    self.model = AutoModel.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
        "    self.linear_1 = torch.nn.Linear(768*512, 512)\n",
        "    self.linear_2 = torch.nn.Linear(512, len(codes))\n",
        "\n",
        "    for param in self.model.base_model.parameters():\n",
        "      param.requires_grad = False\n",
        "\n",
        "  def forward(self, ids, mask):\n",
        "    output = self.model(ids, attention_mask = mask)\n",
        "    linear_output_1 = torch.relu(self.linear_1(output[0].view(batch_size, -1)))\n",
        "    linear_output_2 = torch.sigmoid(self.linear_2(linear_output_1))\n",
        "\n",
        "    return linear_output_2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaUtyijPP4t4"
      },
      "source": [
        "model = BioBERT()\n",
        "model.to(torch.device(\"cuda\"))\n",
        "# criterion = BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8raemPgd5FWw"
      },
      "source": [
        "# Store our loss and accuracy for plotting\n",
        "train_loss_set = []\n",
        "max_val_f1score = 0.0\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 3\n",
        "\n",
        "# trange is a tqdm wrapper around the normal python range\n",
        "for _ in trange(epochs, desc = \"Epoch\"):\n",
        "\n",
        "  # Training\n",
        "  \n",
        "  # Set our model to training mode (as opposed to evaluation mode)\n",
        "  # model.train()\n",
        "\n",
        "  # Tracking variables\n",
        "  tr_loss = 0 #running loss\n",
        "  nb_tr_examples, nb_tr_steps = 0, 0\n",
        "  \n",
        "  # Train the data for one epoch\n",
        "  for step, batch in enumerate(train_dataloader):\n",
        "    batch = tuple(t.to(device) for t in batch) # Add batch to GPU\n",
        "    # b_input_ids, b_input_mask, b_labels, b_token_types = batch # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch # Unpack the inputs from our dataloader\n",
        "    optimizer.zero_grad() # Clear out the gradients (by default they accumulate)\n",
        "    output = model(b_input_ids, b_input_mask) # Forward pass for multilabel classification\n",
        "    loss_func = BCEWithLogitsLoss() \n",
        "    loss = loss_func(output.view(-1, len(codes)), b_labels.type_as(output).view(-1, len(codes))) #convert labels to float for calculation\n",
        "    train_loss_set.append(loss.item())    \n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Update tracking variables\n",
        "    tr_loss += loss.item()\n",
        "    nb_tr_examples += b_input_ids.size(0)\n",
        "    nb_tr_steps += 1\n",
        "\n",
        "  print(\"\\nTrain loss: {}\".format(tr_loss/nb_tr_steps))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BG-Nbbfu54Jh"
      },
      "source": [
        "  # Validation\n",
        "\n",
        "  # Put model in evaluation mode to evaluate loss on the validation set\n",
        "  model.eval()\n",
        "\n",
        "  # Variables to gather full output\n",
        "  logit_preds, true_labels, pred_labels, tokenized_texts = [], [], [], []\n",
        "\n",
        "  for i, batch in enumerate(val_dataloader):\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    # b_input_ids, b_input_mask, b_labels, b_token_types = batch\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "    with torch.no_grad():\n",
        "      b_logit_pred = model(b_input_ids, b_input_mask) # Forward pass for multilabel classification\n",
        "      pred_label = b_logit_pred\n",
        "\n",
        "      b_logit_pred = b_logit_pred.detach().cpu().numpy()\n",
        "      pred_label = pred_label.to('cpu').numpy()\n",
        "      b_labels = b_labels.to('cpu').numpy()\n",
        "\n",
        "    tokenized_texts.append(b_input_ids)\n",
        "    logit_preds.append(b_logit_pred)\n",
        "    true_labels.append(b_labels)\n",
        "    pred_labels.append(pred_label)\n",
        "\n",
        "  # Flatten outputs\n",
        "  pred_labels = [item for sublist in pred_labels for item in sublist]\n",
        "  true_labels = [item for sublist in true_labels for item in sublist]\n",
        "\n",
        "  # Calculate Accuracy\n",
        "  pred_bools = [pl > threshold for pl in pred_labels]\n",
        "  true_bools = [tl == 1 for tl in true_labels]\n",
        "\n",
        "  val_f1_accuracy = f1_score(true_bools, pred_bools,average = 'macro')\n",
        "  val_flat_accuracy = accuracy_score(true_bools, pred_bools)\n",
        "  val_hamming_score = hamming_score(np.array(true_bools), np.array(pred_bools))\n",
        "\n",
        "  # if (max_val_f1score <= val_f1_accuracy):\n",
        "  #   torch.save(model.state_dict(), 'gdrive/MyDrive/BEST_BertModel.pt')\n",
        "\n",
        "  print('\\nF1 Validation Accuracy: ', val_f1_accuracy)\n",
        "  print('Flat Validation Accuracy: ', val_flat_accuracy)\n",
        "  print(\"Validation Hamming Score \", val_hamming_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFyvepth2-l0"
      },
      "source": [
        "  # Testing\n",
        "\n",
        "  # Put model in evaluation mode to evaluate loss on the validation set\n",
        "  model.eval()\n",
        "\n",
        "  # Variables to gather full output\n",
        "  logit_preds, true_labels, pred_labels, tokenized_texts = [], [], [], []\n",
        "\n",
        "  for i, batch in enumerate(test_dataloader):\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    # b_input_ids, b_input_mask, b_labels, b_token_types = batch\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "    with torch.no_grad():\n",
        "      b_logit_pred = model(b_input_ids, b_input_mask) # Forward pass for multilabel classification\n",
        "      pred_label = b_logit_pred\n",
        "\n",
        "      b_logit_pred = b_logit_pred.detach().cpu().numpy()\n",
        "      pred_label = pred_label.to('cpu').numpy()\n",
        "      b_labels = b_labels.to('cpu').numpy()\n",
        "\n",
        "    tokenized_texts.append(b_input_ids)\n",
        "    logit_preds.append(b_logit_pred)\n",
        "    true_labels.append(b_labels)\n",
        "    pred_labels.append(pred_label)\n",
        "\n",
        "  # Flatten outputs\n",
        "  pred_labels = [item for sublist in pred_labels for item in sublist]\n",
        "  true_labels = [item for sublist in true_labels for item in sublist]\n",
        "\n",
        "  # Calculate Accuracy\n",
        "  pred_bools = [pl > threshold for pl in pred_labels]\n",
        "  true_bools = [tl == 1 for tl in true_labels]\n",
        "\n",
        "  test_f1_accuracy = f1_score(true_bools, pred_bools,average = 'macro')\n",
        "  test_flat_accuracy = accuracy_score(true_bools, pred_bools)\n",
        "  test_hamming_score = hamming_score(np.array(true_bools), np.array(pred_bools))\n",
        "\n",
        "  # if (max_val_f1score <= val_f1_accuracy):\n",
        "  #   torch.save(model.state_dict(), 'gdrive/MyDrive/BEST_BertModel.pt')\n",
        "\n",
        "  print('\\nF1 Validation Accuracy: ', val_f1_accuracy)\n",
        "  print('Flat Validation Accuracy: ', val_flat_accuracy)\n",
        "  print(\"Validation Hamming Score \", val_hamming_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0Lw7OhHYPGj"
      },
      "source": [
        "# **D-subtask** *English*: **BioBERT Model for Discharge Summaries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flECZfgpYZU2"
      },
      "source": [
        "def hamming_score(y_true, y_pred):\n",
        "    ''' Compute the Hamming score (a.k.a. label-based accuracy) for the multi-label case\n",
        "        http://stackoverflow.com/q/32239577/395857 '''\n",
        "\n",
        "    acc_list = []\n",
        "    for i in range(y_true.shape[0]):\n",
        "        set_true = set(np.where(y_true[i])[0])\n",
        "        set_pred = set(np.where(y_pred[i])[0])\n",
        "        tmp_a = None\n",
        "        if len(set_true) == 0 and len(set_pred) == 0:\n",
        "            tmp_a = 1\n",
        "        else:\n",
        "            tmp_a = len(set_true.intersection(set_pred))/float(len(set_true.union(set_pred)))\n",
        "        acc_list.append(tmp_a)\n",
        "    return np.mean(acc_list)   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "budu0KLoZyx6"
      },
      "source": [
        "from transformers import AdamW\n",
        "from transformers import AutoTokenizer, AutoModel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-RU_w38Ycrr"
      },
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_Discharge_Summary_BERT\")\n",
        "\n",
        "encodings_train = tokenizer.batch_encode_plus(X_train, max_length = 512, padding = True, truncation = True)\n",
        "encodings_val = tokenizer.batch_encode_plus(X_val, max_length = 512, padding = True, truncation = True)\n",
        "encodings_test = tokenizer.batch_encode_plus(X_test, max_length = 512, padding = True, truncation = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCjor52QYmPp"
      },
      "source": [
        "# Convert all of our data into torch tensors, the required datatype for our model\n",
        "train_inputs = torch.tensor(encodings_train['input_ids'])\n",
        "train_labels = torch.tensor(Y_train)\n",
        "train_masks = torch.tensor(encodings_train['attention_mask'])\n",
        "# train_token_types = torch.tensor(encodings_train['token_type_ids'])\n",
        "\n",
        "val_inputs = torch.tensor(encodings_val['input_ids'])\n",
        "val_labels = torch.tensor(Y_val)\n",
        "val_masks = torch.tensor(encodings_val['attention_mask'])\n",
        "# val_token_types = torch.tensor(encodings_val['token_type_ids'])\n",
        "\n",
        "test_inputs = torch.tensor(encodings_test['input_ids'])\n",
        "test_labels = torch.tensor(Y_test)\n",
        "test_masks = torch.tensor(encodings_test['attention_mask'])\n",
        "# test_token_types = torch.tensor(encodings_test['token_type_ids'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikilHQuLYpCJ"
      },
      "source": [
        "batch_size = 5\n",
        "\n",
        "# train_data = TensorDataset(train_inputs, train_masks, train_labels, train_token_types)\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler = train_sampler, batch_size = batch_size)\n",
        "\n",
        "# val_data = TensorDataset(val_inputs, val_masks, val_labels, val_token_types)\n",
        "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size = batch_size)\n",
        "\n",
        "# test_data = TensorDataset(test_inputs, test_masks, test_labels, test_token_types)\n",
        "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
        "test_sampler = SequentialSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler = test_sampler, batch_size = batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rwR4uZmYsKD"
      },
      "source": [
        "class BioBERT(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(BioBERT, self).__init__()\n",
        "    self.model = AutoModel.from_pretrained(\"emilyalsentzer/Bio_Discharge_Summary_BERT\")\n",
        "    self.linear_1 = torch.nn.Linear(768*512, 700)\n",
        "    self.linear_2 = torch.nn.Linear(700, len(codes))\n",
        "\n",
        "    for param in self.model.base_model.parameters():\n",
        "      param.requires_grad = False\n",
        "\n",
        "  def forward(self, ids, mask):\n",
        "    output = self.model(ids, attention_mask = mask)\n",
        "    linear_output_1 = torch.relu(self.linear_1(output[0].view(batch_size, -1)))\n",
        "    linear_output_2 = torch.sigmoid(self.linear_2(linear_output_1))\n",
        "\n",
        "    return linear_output_2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLhK7J4WYyh5"
      },
      "source": [
        "model = BioBERT()\n",
        "model.to(torch.device(\"cuda\"))\n",
        "# criterion = BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IK3J4W0JY1cZ"
      },
      "source": [
        "# Store our loss and accuracy for plotting\n",
        "train_loss_set = []\n",
        "max_val_f1score = 0.0\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 4\n",
        "\n",
        "# trange is a tqdm wrapper around the normal python range\n",
        "for _ in trange(epochs, desc = \"Epoch\"):\n",
        "\n",
        "  # Training\n",
        "  \n",
        "  # Set our model to training mode (as opposed to evaluation mode)\n",
        "  # model.train()\n",
        "\n",
        "  # Tracking variables\n",
        "  tr_loss = 0 #running loss\n",
        "  nb_tr_examples, nb_tr_steps = 0, 0\n",
        "  \n",
        "  # Train the data for one epoch\n",
        "  for step, batch in enumerate(train_dataloader):\n",
        "    batch = tuple(t.to(device) for t in batch) # Add batch to GPU\n",
        "    # b_input_ids, b_input_mask, b_labels, b_token_types = batch # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch # Unpack the inputs from our dataloader\n",
        "    optimizer.zero_grad() # Clear out the gradients (by default they accumulate)\n",
        "    output = model(b_input_ids, b_input_mask) # Forward pass for multilabel classification\n",
        "    loss_func = BCEWithLogitsLoss() \n",
        "    loss = loss_func(output.view(-1, len(codes)), b_labels.type_as(output).view(-1, len(codes))) #convert labels to float for calculation\n",
        "    train_loss_set.append(loss.item())    \n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Update tracking variables\n",
        "    tr_loss += loss.item()\n",
        "    nb_tr_examples += b_input_ids.size(0)\n",
        "    nb_tr_steps += 1\n",
        "\n",
        "  print(\"\\nTrain loss: {}\".format(tr_loss/nb_tr_steps))\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  # Variables to gather full output\n",
        "  logit_preds, true_labels, pred_labels, tokenized_texts = [], [], [], []\n",
        "\n",
        "  for i, batch in enumerate(val_dataloader):\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    # b_input_ids, b_input_mask, b_labels, b_token_types = batch\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "    with torch.no_grad():\n",
        "      b_logit_pred = model(b_input_ids, b_input_mask) # Forward pass for multilabel classification\n",
        "      pred_label = b_logit_pred\n",
        "\n",
        "      b_logit_pred = b_logit_pred.detach().cpu().numpy()\n",
        "      pred_label = pred_label.to('cpu').numpy()\n",
        "      b_labels = b_labels.to('cpu').numpy()\n",
        "\n",
        "    tokenized_texts.append(b_input_ids)\n",
        "    logit_preds.append(b_logit_pred)\n",
        "    true_labels.append(b_labels)\n",
        "    pred_labels.append(pred_label)\n",
        "\n",
        "  # Flatten outputs\n",
        "  pred_labels = [item for sublist in pred_labels for item in sublist]\n",
        "  true_labels = [item for sublist in true_labels for item in sublist]\n",
        "\n",
        "  # Calculate Accuracy\n",
        "  pred_bools = [pl > threshold for pl in pred_labels]\n",
        "  true_bools = [tl == 1 for tl in true_labels]\n",
        "\n",
        "  val_f1_accuracy = f1_score(true_bools, pred_bools,average = 'macro')\n",
        "  val_flat_accuracy = accuracy_score(true_bools, pred_bools)\n",
        "  val_hamming_score = hamming_score(np.array(true_bools), np.array(pred_bools))\n",
        "\n",
        "  print('\\nF1 Validation Accuracy: ', val_f1_accuracy)\n",
        "  print('Flat Validation Accuracy: ', val_flat_accuracy)\n",
        "  print(\"Validation Hamming Score \", val_hamming_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sxbvX5hZFNB"
      },
      "source": [
        "  # Testing\n",
        "\n",
        "  # Put model in evaluation mode to evaluate loss on the validation set\n",
        "  model.eval()\n",
        "\n",
        "  # Variables to gather full output\n",
        "  logit_preds, true_labels, pred_labels, tokenized_texts = [], [], [], []\n",
        "\n",
        "  for i, batch in enumerate(test_dataloader):\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    # b_input_ids, b_input_mask, b_labels, b_token_types = batch\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "    with torch.no_grad():\n",
        "      b_logit_pred = model(b_input_ids, b_input_mask) # Forward pass for multilabel classification\n",
        "      pred_label = b_logit_pred\n",
        "\n",
        "      b_logit_pred = b_logit_pred.detach().cpu().numpy()\n",
        "      pred_label = pred_label.to('cpu').numpy()\n",
        "      b_labels = b_labels.to('cpu').numpy()\n",
        "\n",
        "    tokenized_texts.append(b_input_ids)\n",
        "    logit_preds.append(b_logit_pred)\n",
        "    true_labels.append(b_labels)\n",
        "    pred_labels.append(pred_label)\n",
        "\n",
        "  # Flatten outputs\n",
        "  pred_labels = [item for sublist in pred_labels for item in sublist]\n",
        "  true_labels = [item for sublist in true_labels for item in sublist]\n",
        "\n",
        "  # Calculate Accuracy\n",
        "  pred_bools = [pl > threshold for pl in pred_labels]\n",
        "  true_bools = [tl == 1 for tl in true_labels]\n",
        "\n",
        "  test_f1_accuracy = f1_score(true_bools, pred_bools,average = 'macro')\n",
        "  test_flat_accuracy = accuracy_score(true_bools, pred_bools)\n",
        "  test_hamming_score = hamming_score(np.array(true_bools), np.array(pred_bools))\n",
        "\n",
        "  # if (max_val_f1score <= val_f1_accuracy):\n",
        "  #   torch.save(model.state_dict(), 'gdrive/MyDrive/BEST_BertModel.pt')\n",
        "\n",
        "  print('\\nF1 Validation Accuracy: ', val_f1_accuracy)\n",
        "  print('Flat Validation Accuracy: ', val_flat_accuracy)\n",
        "  print(\"Validation Hamming Score \", val_hamming_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9PWFankR5ag"
      },
      "source": [
        "# **P-subtask** *English*: **Data Loader**\n",
        "\n",
        "X_train, X_val, X_test: list of *input text data*\n",
        "\n",
        "Y_train, Y_val, Y_test: list of one-hot encoded *labels*\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Txh0TUItSDep"
      },
      "source": [
        "df_train = pd.read_csv('drive/MyDrive/CodiEsp/train/trainP.tsv', sep = '\\t', header = None)\n",
        "df_train.rename(columns = {0:\"Id\", 1:\"ICD10\"}, inplace = True)\n",
        "print(\"Training Data:\")\n",
        "display(df_train.head())\n",
        "\n",
        "print(\"\\n\\nValidation Data:\")\n",
        "df_val = pd.read_csv('drive/MyDrive/CodiEsp/dev/devP.tsv', sep = '\\t', header = None)\n",
        "df_val.rename(columns = {0:\"Id\", 1:\"ICD10\"}, inplace = True)\n",
        "display(df_val.head())\n",
        "\n",
        "print(\"\\n\\nTest Data:\")\n",
        "df_test = pd.read_csv('drive/MyDrive/CodiEsp/test/testP.tsv', sep = '\\t', header = None)\n",
        "df_test.rename(columns = {0:\"Id\", 1:\"ICD10\"}, inplace = True)\n",
        "display(df_test.head())\n",
        "\n",
        "df = pd.concat([df_train, df_val, df_test])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVofJIzISJdP"
      },
      "source": [
        "ids = df['Id'].unique()\n",
        "codes = df['ICD10'].unique()  \n",
        "\n",
        "print(\"Number of documents in training data:\", len(\n",
        "    ids), \"\\nNumber of ICD10 codes:\", len(codes))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsKRwpebSJ3f"
      },
      "source": [
        "code2idx = {}\n",
        "for i in range(len(codes)):\n",
        "  code2idx[codes[i]] = i\n",
        "\n",
        "id2label = {}\n",
        "for i in range(len(ids)):\n",
        "  id2label[ids[i]] = [0]*len(codes)\n",
        "\n",
        "for i, data in df.iterrows():\n",
        "  _id = data[0]\n",
        "  _code = data[1]\n",
        "  id2label[_id][code2idx[_code]] = 1\n",
        "\n",
        "_id2label = [(id, y) for id, y in id2label.items()]\n",
        "ID, Y = zip(*_id2label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEHG7aRvSOBX"
      },
      "source": [
        "def remstopwords(text, stopwords):\n",
        "    text = re.sub('\\[\\*\\*[^\\]]*\\*\\*\\]', '', text)\n",
        "    text = re.sub('<[^>]*>', '', text)\n",
        "    text = re.sub('[\\W]+', ' ', text.lower()) \n",
        "    text = re.sub(\" \\d+\", \" \", text)\n",
        "    return \" \".join([i for i in text.split() if i not in stopwords])\n",
        "\n",
        "stop_words = stopwords.words('english')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oV9MFl3BSOl2"
      },
      "source": [
        "X_train = []\n",
        "Y_train = []\n",
        "\n",
        "for id in (df_train['Id'].unique()):\n",
        "  Y_train.append(id2label[id])\n",
        "  with open('drive/MyDrive/CodiEsp/train/text_files_en/' + id + '.txt', 'r') as f:\n",
        "    text = f.read().replace('\\n', ' ')\n",
        "  X_train.append(remstopwords(text.lower(), stop_words))\n",
        "\n",
        "\n",
        "with open(\"drive/MyDrive/X_train_P.txt\", \"wb\") as fp:\n",
        "  pickle.dump(X_train, fp)\n",
        "\n",
        "with open(\"drive/MyDrive/X_train_P.txt\", \"rb\") as fp:\n",
        "  X_train = pickle.load(fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86DGNqD8SRIa"
      },
      "source": [
        "X_val = []\n",
        "Y_val = []\n",
        "\n",
        "for id in (df_val['Id'].unique()):\n",
        "  Y_val.append(id2label[id])\n",
        "  with open('drive/MyDrive/CodiEsp/dev/text_files_en/' + id + '.txt', 'r') as f:\n",
        "    text = f.read().replace('\\n', ' ')\n",
        "  X_val.append(remstopwords(text.lower(), stop_words))\n",
        "\n",
        "\n",
        "with open(\"drive/MyDrive/X_val_P.txt\", \"wb\") as fp:\n",
        "  pickle.dump(X_val, fp)\n",
        "with open(\"drive/MyDrive/X_val_P.txt\", \"rb\") as fp:\n",
        "  X_val = pickle.load(fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFREya_ySTbX"
      },
      "source": [
        "X_test = []\n",
        "Y_test = []\n",
        "\n",
        "for id in (df_test['Id'].unique()):\n",
        "  Y_test.append(id2label[id])\n",
        "\n",
        "  with open('drive/MyDrive/CodiEsp/test/text_files_en/' + id + '.txt', 'r') as f:\n",
        "    text = f.read().replace('\\n', ' ')\n",
        "  X_test.append(remstopwords(text.lower(), stop_words))\n",
        "\n",
        "\n",
        "with open(\"drive/MyDrive/X_test_P.txt\", \"wb\") as fp:\n",
        "  pickle.dump(X_test, fp)\n",
        "with open(\"drive/MyDrive/X_test_P.txt\", \"rb\") as fp:\n",
        "  X_test = pickle.load(fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZr5fj3RSVf9"
      },
      "source": [
        "p_code = [0]*len(codes)\n",
        "for label in Y_train:\n",
        "  for i, code in enumerate(label):\n",
        "    if (code == 1):\n",
        "      p_code[i] = 1\n",
        "\n",
        "not_present = 0\n",
        "for i, present in enumerate(p_code):\n",
        "  if (present == 0):\n",
        "    not_present += 1\n",
        "\n",
        "print(\"Number of classes NOT PRESENT in training dataset:\", not_present)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dc9vfOvsSbrH"
      },
      "source": [
        "# **P-subtask** *English*: **BERT Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaVPG-InSmn2"
      },
      "source": [
        "from transformers import AdamW\n",
        "from transformers import BertTokenizer, BertForSequenceClassification"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNEuFDXTSkvG"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case = True)\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels = len(codes))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYpgsLHqSzaf"
      },
      "source": [
        "encodings_train = tokenizer.batch_encode_plus(X_train, max_length = 512, padding = True, truncation = True)\n",
        "encodings_val = tokenizer.batch_encode_plus(X_val, max_length = 512, padding = True, truncation = True)\n",
        "encodings_test = tokenizer.batch_encode_plus(X_test, max_length = 512, padding = True, truncation = True)\n",
        "\n",
        "print('tokenizer outputs: ', encodings_train.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkfkzOgrSrXu"
      },
      "source": [
        "# Convert all of our data into torch tensors, the required datatype for our model\n",
        "train_inputs = torch.tensor(encodings_train['input_ids'])\n",
        "train_labels = torch.tensor(Y_train)\n",
        "train_masks = torch.tensor(encodings_train['attention_mask'])\n",
        "train_token_types = torch.tensor(encodings_train['token_type_ids'])\n",
        "\n",
        "val_inputs = torch.tensor(encodings_val['input_ids'])\n",
        "val_labels = torch.tensor(Y_val)\n",
        "val_masks = torch.tensor(encodings_val['attention_mask'])\n",
        "val_token_types = torch.tensor(encodings_val['token_type_ids'])\n",
        "\n",
        "test_inputs = torch.tensor(encodings_test['input_ids'])\n",
        "test_labels = torch.tensor(Y_test)\n",
        "test_masks = torch.tensor(encodings_test['attention_mask'])\n",
        "test_token_types = torch.tensor(encodings_test['token_type_ids'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOVO8z3zSuVP"
      },
      "source": [
        "batch_size = 5\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels, train_token_types)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size = batch_size)\n",
        "\n",
        "val_data = TensorDataset(val_inputs, val_masks, val_labels, val_token_types)\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size = batch_size)\n",
        "\n",
        "test_data = TensorDataset(test_inputs, test_masks, test_labels, test_token_types)\n",
        "test_sampler = SequentialSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size = batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxkCq8ZVS6Me"
      },
      "source": [
        "model.cuda(device = device);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MM_NajjHS6ln"
      },
      "source": [
        "optimizer = AdamW(model.parameters(), lr = 2e-5)  # Default optimization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Twey3IrnS9Nv"
      },
      "source": [
        "for param in model.base_model.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBcywLUBTB2q"
      },
      "source": [
        "def hamming_score(y_true, y_pred):\n",
        "    ''' Compute the Hamming score (a.k.a. label-based accuracy) for the multi-label case\n",
        "        http://stackoverflow.com/q/32239577/395857 '''\n",
        "\n",
        "    acc_list = []\n",
        "    for i in range(y_true.shape[0]):\n",
        "        set_true = set(np.where(y_true[i])[0])\n",
        "        set_pred = set(np.where(y_pred[i])[0])\n",
        "        tmp_a = None\n",
        "        if len(set_true) == 0 and len(set_pred) == 0:\n",
        "            tmp_a = 1\n",
        "        else:\n",
        "            tmp_a = len(set_true.intersection(set_pred))/float(len(set_true.union(set_pred)))\n",
        "        acc_list.append(tmp_a)\n",
        "    return np.mean(acc_list)   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEqtxCfRTCXn"
      },
      "source": [
        "# Store our loss and accuracy for plotting\n",
        "train_loss_set = []\n",
        "max_val_f1score = 0.0\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 4\n",
        "\n",
        "# trange is a tqdm wrapper around the normal python range\n",
        "for _ in trange(epochs, desc = \"Epoch\"):\n",
        "\n",
        "  # Training\n",
        "  \n",
        "  # Set our model to training mode (as opposed to evaluation mode)\n",
        "  model.train()\n",
        "\n",
        "  # Tracking variables\n",
        "  tr_loss = 0 #running loss\n",
        "  nb_tr_examples, nb_tr_steps = 0, 0\n",
        "  \n",
        "  # Train the data for one epoch\n",
        "  for step, batch in enumerate(train_dataloader):\n",
        "    batch = tuple(t.to(device) for t in batch) # Add batch to GPU\n",
        "    b_input_ids, b_input_mask, b_labels, b_token_types = batch # Unpack the inputs from our dataloader\n",
        "    optimizer.zero_grad() # Clear out the gradients (by default they accumulate)\n",
        "\n",
        "    outputs = model(b_input_ids, token_type_ids = None, attention_mask = b_input_mask) # Forward pass for multilabel classification\n",
        "\n",
        "    logits = outputs[0]\n",
        "    loss_func = BCEWithLogitsLoss() \n",
        "    loss = loss_func(logits.view(-1, len(codes)), b_labels.type_as(logits).view(-1, len(codes))) #convert labels to float for calculation\n",
        "    train_loss_set.append(loss.item())    \n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Update tracking variables\n",
        "    tr_loss += loss.item()\n",
        "    nb_tr_examples += b_input_ids.size(0)\n",
        "    nb_tr_steps += 1\n",
        "\n",
        "  print(\"\\nTrain loss: {}\".format(tr_loss/nb_tr_steps))\n",
        "\n",
        "###############################################################################\n",
        "\n",
        "  # Validation\n",
        "\n",
        "  # Put model in evaluation mode to evaluate loss on the validation set\n",
        "  model.eval()\n",
        "\n",
        "  # Variables to gather full output\n",
        "  logit_preds, true_labels, pred_labels, tokenized_texts = [], [], [], []\n",
        "\n",
        "  for i, batch in enumerate(val_dataloader):\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    b_input_ids, b_input_mask, b_labels, b_token_types = batch\n",
        "    \n",
        "    with torch.no_grad():\n",
        "      outs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "      b_logit_pred = outs[0]\n",
        "      pred_label = torch.sigmoid(b_logit_pred)\n",
        "\n",
        "      b_logit_pred = b_logit_pred.detach().cpu().numpy()\n",
        "      pred_label = pred_label.to('cpu').numpy()\n",
        "      b_labels = b_labels.to('cpu').numpy()\n",
        "\n",
        "    tokenized_texts.append(b_input_ids)\n",
        "    logit_preds.append(b_logit_pred)\n",
        "    true_labels.append(b_labels)\n",
        "    pred_labels.append(pred_label)\n",
        "\n",
        "  # Flatten outputs\n",
        "  pred_labels = [item for sublist in pred_labels for item in sublist]\n",
        "  true_labels = [item for sublist in true_labels for item in sublist]\n",
        "\n",
        "  # Calculate Accuracy\n",
        "  pred_bools = [pl > threshold for pl in pred_labels]\n",
        "  true_bools = [tl == 1 for tl in true_labels]\n",
        "\n",
        "  val_f1_accuracy = f1_score(true_bools, pred_bools,average = 'macro')\n",
        "  val_flat_accuracy = accuracy_score(true_bools, pred_bools)\n",
        "  val_hamming_score = hamming_score(np.array(true_bools), np.array(pred_bools))\n",
        "\n",
        "  # if (max_val_f1score <= val_f1_accuracy):\n",
        "  #   torch.save(model.state_dict(), 'drive/MyDrive/BEST_BertModel.pt')\n",
        "\n",
        "  print('\\nF1 Validation Accuracy: ', val_f1_accuracy)\n",
        "  print('Flat Validation Accuracy: ', val_flat_accuracy)\n",
        "  print(\"Validation Hamming Score \", val_hamming_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rgkcDE2THLW"
      },
      "source": [
        "torch.save(model.state_dict(), 'drive/MyDrive/BEST_BertModelP.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_fyUhwiTHwp"
      },
      "source": [
        "# model.load_state_dict(torch.load('drive/MyDrive/BEST_BertModelP.pt'))\n",
        "model.eval()\n",
        "\n",
        "# Variables to gather full output\n",
        "logit_preds, true_labels, pred_labels, tokenized_texts = [], [], [], []\n",
        "\n",
        "for i, batch in enumerate(test_dataloader):\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  b_input_ids, b_input_mask, b_labels, b_token_types = batch\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    outs = model(b_input_ids, token_type_ids = None, attention_mask = b_input_mask)\n",
        "    b_logit_pred = outs[0]\n",
        "    pred_label = torch.sigmoid(b_logit_pred)\n",
        "\n",
        "    b_logit_pred = b_logit_pred.detach().cpu().numpy()\n",
        "    pred_label = pred_label.to('cpu').numpy()\n",
        "    b_labels = b_labels.to('cpu').numpy()\n",
        "\n",
        "  tokenized_texts.append(b_input_ids)\n",
        "  logit_preds.append(b_logit_pred)\n",
        "  true_labels.append(b_labels)\n",
        "  pred_labels.append(pred_label)\n",
        "\n",
        "# Flatten outputs\n",
        "pred_labels = [item for sublist in pred_labels for item in sublist]\n",
        "true_labels = [item for sublist in true_labels for item in sublist]\n",
        "\n",
        "# Calculate Accuracy\n",
        "pred_bools = [pl > threshold for pl in pred_labels]\n",
        "true_bools = [tl == 1 for tl in true_labels]\n",
        "\n",
        "test_f1_accuracy = f1_score(true_bools, pred_bools,average = 'macro')\n",
        "test_flat_accuracy = accuracy_score(true_bools, pred_bools)\n",
        "test_hamming_score = hamming_score(np.array(true_bools), np.array(pred_bools))\n",
        "\n",
        "print('\\nF1 Test Accuracy: ', test_f1_accuracy)\n",
        "print('Flat Test Accuracy: ', test_flat_accuracy)\n",
        "print(\"Test Hamming Score \", test_hamming_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTPrgoisQiPy"
      },
      "source": [
        "# References\n",
        "\n",
        "\n",
        "https://towardsdatascience.com/transformers-for-multilabel-classification-71a1a0daf5e1\n",
        "\n",
        "https://huggingface.co/emilyalsentzer/Bio_ClinicalBERT\n",
        "\n",
        "http://stackoverflow.com/q/32239577/395857\n"
      ]
    }
  ]
}